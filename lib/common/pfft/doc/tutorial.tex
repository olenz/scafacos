%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Tutorial}\label{chap:tuto}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The following chapter describes the usage of the PFFT library corresponding to the simple test files,
that are included in the library. If you are interested in the more advanced features of PFFT you
should also have a look at Chapter~\ref{chap:feat}.

\section{A first parallel transform - Three-dimensional FFT with two-dimensional data decomposition}
We explain the basic steps for computing a parallel FFT with the PFFT library at the example
of the short test program given by Listing~\ref{lst:min_c2c}. This test computes a three-dimensional c2c-FFT on
a two-dimensional process mesh. The source code can also be found in directory \code{tests/}
of the library's source code tree. 
\lstinputlisting[numbers=left, float, caption={Minimal parallel c2c-FFT test program.}, label=lst:min_c2c]{code/manual_min_c2c.c}

After initializing MPI with \code{MPI_Init} and before calling any other PFFT routine initialize
the parallel computations via
\begin{lstlisting}
void pfft_init(void);
\end{lstlisting}
MPI introduces the concept of communicators to store all the topological information of the physical process layout.
PFFT requires to be called on a process mesh that corresponds to a periodic, Cartesian communicator.
We assist the user in creating such a communicator with the following routine
\begin{lstlisting}
int pfft_create_procmesh_2d(
    MPI_Comm comm, int np0, int np1,
    MPI_Comm *comm_cart_2d);
\end{lstlisting}
This routine uses the processes within the communicator \code{comm} to create a two-dimensional process
grid of size \code{np0} x \code{np1} and stores it into the Cartesian communicator \code{comm\_cart\_2d}.
Since \code{comm\_cart\_2d} is allocated by the routine, the user has to provide
the pointer to a non-allocated communicator. Otherwise we end up with a memory leak.
Most users will choose \code{comm} as \code{MPI\_COMM\_WORLD}, which implies that the FFT is computed
on all available processes. Nevertheless, it's important to note, that we follow the principles of MPI
by allowing \code{comm} to be any arbitrary communicator and therefore any subset of all available processes.

At the next step we need to know the data decomposition of the input and output array, that depends on
the array sizes, the process grid and the chosen parallel algorithm. Therefore, we call
\begin{lstlisting}
ptrdiff_t pfft_local_size_3d(
    ptrdiff_t *n, MPI_Comm comm_cart_2d, unsigned pfft_flags,
    ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
    ptrdiff_t *local_no, ptrdiff_t *local_o_start);
\end{lstlisting}
Hereby, \code{n}, \code{local_ni}, \code{local_i_start}, \code{local_no}, \code{local_o_start} are arrays of length $3$.
This function returns the size of the local complex array that needs to be allocated by every process.
In most cases, this coincides with the product of the local array sizes -- but may be bigger,
whenever the parallel algorithm needs some extra storage.
The input value \code{n} gives the three-dimensional FFT size and the flag \code{pfft_flags} serves to adjust
some details of the parallel execution. For the sake of simplicity, we restrict our self to the case
\code{pfft_flags=PFFT_TRANSPOSED_NONE} for a while and explain the more sophisticated flags at a later point.
The output arrays \code{local_ni} and \code{local_i_start} give the size and the offset of the local input array
that result from the parallel block distribution of the global input array, i.e.,
every process owns the input data \code{in[k[0],k[1],k[2]]} with \code{local_i_start[t] <= k[t] < local_i_start[t] + local_ni[t]}
for \code{t=0,1,2}. Analogously, the output parameters \code{local_i_start} and \code{local_no} contain the size
and the offset of the local output array.

Next the input and output arrays must be allocated. For performance reasons this should be done using
\begin{lstlisting}
pfft_complex* pfft_alloc_complex(size_t size);
\end{lstlisting}
Nevertheless, you can also use any other dynamic memory allocation. Have a look at the FFTW user manual~\cite{fftw-align-mem}
for more details on SIMD alignment and \code{fftw_malloc}, which is called within all PFFT allocation functions.

The planning of a single three-dimensional parallel FFT of size \code{n[0]} x \code{n[1]} x \code{n[2]}
is done by the function
\begin{lstlisting}
pfft_plan pfft_plan_dft_3d(
    ptrdiff_t *n, pfft_complex *in, pfft_complex *out,
    MPI_Comm comm_cart_2d, int sign, unsigned pfft_flags);
\end{lstlisting}
We provide the address of the input and output array by the pointers \code{in} and \code{out},
respectively. An inplace transform is assumed if these pointers are equal. 
Similar to FFTW the integer \code{sign} gives the sign in the exponential of the FFT.
The \code{pfft\_flags} must coincide with the flags that were used to call \code{pfft_local_size_3d}.
Otherwise the data layout of the parallel execution may not match calculated local array sizes.
This function returns a plan, some structure that includes all the information we need to perform a
parallel FFT.

Once the plan is generated, we are allowed to fill the input array \code{in}. Note, that in most cases
the planning \code{pfft_plan_dft_3d} would overwrite the input array \code{in}. That's you should not
write any sensitive data into \code{in} until the plan was generated.
For simplicity, our test program makes use of the library function
\begin{lstlisting}
void pfft_init_input_c2c_3d(
    ptrdiff_t *n, ptrdiff_t *local_ni, ptrdiff_t *local_i_start,
    pfft_complex *in);
\end{lstlisting}
to fill the input array with some numbers. Alternatively, one can fill the array with a function \code{func} of choice
and the following loop that takes account of the parallel data layout
\begin{lstlisting}
ptrdiff_t m=0;
for(ptrdiff_t k0=0; k0 < local_ni[0]; k0++)
  for(ptrdiff_t k1=0; k1 < local_ni[1]; k1++)
    for(ptrdiff_t k2=0; k2 < local_ni[2]; k2++)
      in[m++] = func(k0 + local_i_start[0],
                     k1 + local_i_start[1],
                     k2 + local_i_start[2]);
\end{lstlisting}
The parallel FFT is computed at the moment we execute the generated plan
\begin{lstlisting}
void pfft_execute(pfft_plan plan);
\end{lstlisting}
Now, the results can be read from \code{out} with an analogous three-dimensional loop.
If we do not want to execute another parallel FFT of the same type, we free the allocated memory of the plan with
\begin{lstlisting}
void pfft_destroy_plan(pfft_plan plan);
\end{lstlisting}
Additionally, we use
\begin{lstlisting}
int MPI_Comm_free(MPI_Comm *comm);  
\end{lstlisting}
to free the communicator allocated by \code{pfft_create_procmesh_2d} and
\begin{lstlisting}
void pfft_free(void *ptr);
\end{lstlisting}
to free memory allocated by \code{pfft_alloc_complex}.
Finally, we exit MPI by
\begin{lstlisting}
int MPI_Finalize(void);
\end{lstlisting}

\section{More sophisticated options}

\subsection{Errorcode for communicator creation}
As we have seen the function
\begin{lstlisting}
int pfft_create_procmesh_2d(
    MPI_Comm comm, int np0, int np1,
    MPI_Comm *comm_cart_2d);
\end{lstlisting}
creates a two-dimensional, periodic, Cartesian communicator. The \code{int} return value
(not used in Listing~\ref{lst:min_c2c}) is the forwarded error code of \code{MPI_Cart_create}.
It is equal to zero if the communicator was created successfully.
The most common error is that the number of processes within the input
communicator \code{comm} does not fit \code{np0 x np1}. In this case the Cartesian communicator
is not generated and the return value is unequal to zero. Therefore, a typical sanity check might look like
\begin{lstlisting}
/* Create two-dimensional process grid of size np[0] x np[1],
   if possible */
if( pfft_create_procmesh_2d(MPI_COMM_WORLD, np[0], np[1],
        &comm_cart_2d) )
{
  pfft_fprintf(MPI_COMM_WORLD, stderr,
      "Error: This test file only works with %d processes.\n",
      np[0]*np[1]);
  MPI_Finalize();
  return 1;
}
\end{lstlisting}
Hereby, we print the error message with the help of the PFFT library function \code{pfft_fprintf}; see Section~\ref{sec:fprintf} for details.
\begin{lstlisting}
void pfft_fprintf(
    MPI_Comm comm, FILE *stream, const char *format, ...);
\end{lstlisting}
This function is similar to the standard C function \code{fprintf} with the exception, that all messages are restricted
to the process of rank $0$ within the given communicator \code{comm}.

\subsection{Inplace transforms}
Similar to FFTW, PFFT is able to compute parallel FFTs completely in place, which means that beside some
constant buffers, no second data array beside the inputs is necessary. Especially, the global data communication
can be performed in place. As far as we know, there is no other parallel FFT library beside FFTW and PFFT that
supports this feature. 
This feature is enabled as soon as the pointer to the output array \code{out} is equal to the pointer to the input array \code{in}.
E.g., in Listing~\ref{lst:min_c2c} we would call
\begin{lstlisting}[firstnumber=34]
/* Plan parallel forward FFT */
plan = pfft_plan_dft_3d(n, in, in, comm_cart_2d,
    PFFT_FORWARD, PFFT_TRANSPOSED_NONE);
\end{lstlisting}

\subsection{PFFT flags}
\begin{compactitem}
  \item \code{PFFT_TRANSPOSED_IN}
  \item \code{PFFT_TRANSPOSED_OUT}
  \item \code{PFFT_SHIFTED_IN}
  \item \code{PFFT_SHIFTED_OUT}
  \item \code{PFFT_ESTIMATE}
  \item \code{PFFT_MEASURE}
  \item \code{PFFT_PATIENT}
  \item \code{PFFT_EXHAUSIVE}
  \item \code{PFFT_NO_TUNE}
  \item \code{PFFT_TUNE}
  \item \code{PFFT_PRESERVE_INPUT}
  \item \code{PFFT_DESTROY_INPUT}
  \item \code{PFFT_BUFFERED_INPLACE}
\end{compactitem}


\section{Parallel data distribution}

\section{Three-dimensional FFTs with three-dimensional data decomposition}

\section{Arbitrary dimensional data decomposition}
Our first test program used a two-dimensional data decomposition of a three-dimensional data set.
Moreover, PFFT support the computation of any $d$-dimensional FFT with $r$-dimensional data decomposition
as long as $r\le d-1$. For example, one can use a one-dimensional data decomposition for any two- or higher-dimensional data set,
while the data set must be at least four-dimensional to fit to a three-dimensional data decomposition.
The case $r=d$ is not supported efficiently, since during the parallel computations
there is always at least one dimension that remains local, i.e., one dimensions stays non-decomposed.
However, for the case $d=r=3$ we offer some library

The dimensionality of the data decomposition is given by the dimension of the Cartesian communicator that
goes into the PFFT planing routines. Therefore, we present a generalization of communicator creation function
\begin{lstlisting}
int pfft_create_procmesh(
    int rnk, MPI_Comm comm, const int *np,
    MPI_Comm *comm_cart);
\end{lstlisting}
Hereby, the array \code{np} of length \code{rnk} gives the size of the Cartesian communicator \code{cart_comm}.


\newpage
Transposed $d$-dimensional array distributed on $c$-dimensional process mesh ($c<d$)
\begin{equation*}
  \frac{n_1}{P_0} \times \frac{n_2}{P_1} \times \hdots \times \frac{n_c}{P_{c-1}}  \times n_0 \times n_{c+1} \times \hdots \times n_{d-1}
\end{equation*}

Comparision of non-transposed (left) and transposed (right) $d$-dimensional array for $c$-dimensional process mesh ($c<d$)
\begin{equation*}
  n_0\times n_1\times \hdots n_{c-1} \times n_c \hdots \times n_{d-1} \Rightarrow n_1 \times \hdots n_{c-1} \times n_0 \times n_c \times \hdots \times n_{d-1}
\end{equation*}







% \code{n}
% \code{comm\_cart\_2d}





\section{Parallel FFT Frameworks}

\subsection{Forward Framework A (transposed input)}
\figurename{}~\ref{fig:fft_forw} lists the pseudo code of the parallel forward FFT framework.
\begin{figure}[ht]
  \begin{algorithmic}[1]
  %   \State\Comment{Calculate the serial FFTs row wise}
    \For{$t\gets0,\hdots,d-r-2$}
      \State $h_0 \gets \bigtimes_{s=0}^{r-1} N_s/P_s \times \bigtimes_{s=r}^{d-2-t} N_s$
      \State $N   \gets N_{d-1-t}$
      \State $h_1 \gets \bigtimes_{s=d-t}^{d-1} \hat N_s \times h$
      \State $h_0 \times N \times h_1 \osetarrow{FFT} h_0 \times \hat N \times h_1$
    \EndFor
    \For{$t\gets 0,\hdots,r-1$}
      \State $h_0 \gets \bigtimes_{s=r-t}^{r-1} \hat N_{s+1}/P_s \times \bigtimes_{s=0}^{r-t-1} N_s/P_s$
      \State $N   \gets N_{r-t}$
      \State $h_1 \gets \bigtimes_{s=r+1}^{d-1} \hat N_s \times h$
      \State $h_0 \times N \times h_1 \ousetarrow{FFT}{TO} \hat N \times h_0 \times h_1$
      \State
      \State $L_0 \gets \hat N_{r-t}$
      \State $h_0 \gets \bigtimes_{s=r-t}^{r-1}\hat N_{s+1}/P_{s} \times \bigtimes_{s=0}^{r-t-2} N_s/P_s$
      \State $L_1 \gets N_{r-t-1}$
      \State $h_1 \gets 1$
      \State $h_2 \gets \bigtimes_{s=r+1}^{d-1} \hat N_s \times h$
      \State $P   \gets P_{r-t-1}$
%       \State \mbox{$L_0 \times h_0 \times L_1/P \times h_1 \times h_2$} \mbox{$\ousetarrow{T}{TI} L_0/P \times h_0 \times L_1 \times h_1 \times h_2$}
      \State $L_0 \times h_0 \times L_1/P \times h_1 \times h_2\ousetarrow{T}{TI} L_0/P \times h_0 \times L_1 \times h_1 \times h_2$
    \EndFor
    \State $h_0 \gets \bigtimes_{s=0}^{r-1}\hat N_{s+1}/P_s$
    \State $N   \gets N_0$
    \State $h_1 \gets \bigtimes_{s=r+1}^{d-1} \hat N_s \times h$
    \State $h_0 \times N \times h_1 \osetarrow{FFT} h_0 \times \hat N \times h_1$
  \end{algorithmic}
  \caption{Parallel Forward FFT Framework}\label{fig:fft_forw}
\end{figure}

Within the first loop we use the serial FFT module~\eqref{eq:pruned_fft} to calculate
the one-dimensional (pruned) FFTs along the last $d-r-1$ array dimensions.
In the second loop we calculate $r$ one-dimensional pruned FFTs with transposed output~\eqref{eq:pruned_fft_to}
interleaved by global data transpositions with transposed input~\eqref{eq:gtransp_ti}.
Finally, a single non-transposed FFT~\eqref{eq:pruned_fft} must be computed to finish the full $d$-dimensional FFT.
The data decomposition of the output is then given by
\begin{equation*}
  \hat N_1/P_0 \times \hdots \times \hat N_{r-2}/P_{r-1} \times \hat N_r \times \hdots \times \hat N_{d-1} \times h\,.
\end{equation*}
Note, that the dimensions of the output array are slightly transposed.

\subsection{Backward Framework C (transposed output)}
Now, the parallel backward FFT framework can be derived very easy since we only need to revert all the steps
of the forward framework. The backward framework starts with the output decomposition of the forward framework
\begin{equation*}
  \hat N_1/P_0 \times \hdots \times \hat N_{r-2}/P_{r-1} \times \hat N_r \times \hdots \times \hat N_{d-1} \times h
\end{equation*}
and ends with the initial data decomposition
\begin{equation*}
  N_0/P_0 \times \hdots \times N_{r-1}/P_{r-1} \times N_r \times \hdots \times N_{d-1} \times h\,.
\end{equation*}
\figurename{}~\ref{fig:fft_back} lists the parallel backward FFT framework in pseudo code.
\begin{figure}[ht]
  \begin{algorithmic}[1]
  %   \State\Comment{Calculate the serial FFTs row wise}
    \State $h_0 \gets \bigtimes_{s=0}^{r-1}\hat N_{s+1}/P_s$
    \State $N   \gets \hat N_0$
    \State $h_1 \gets \bigtimes_{s=r+1}^{d-1} \hat N_s \times h$
    \State $h_0 \times \hat N \times h_1 \osetarrow{FFT} h_0 \times N \times h_1$
    \For{$t\gets r-1,\hdots,0$}
      \State $L_1 \gets \hat N_{r-t}$
      \State $h_1 \gets \bigtimes_{s=r-t}^{r-1}\hat N_{s+1}/P_{s} \times \bigtimes_{s=0}^{r-t-2} N_s/P_s$
      \State $L_0 \gets N_{r-t-1}$
      \State $h_0 \gets 1$
      \State $h_2 \gets \bigtimes_{s=r+1}^{d-1} \hat N_s \times h$
      \State $P   \gets P_{r-t-1}$
      \State $L_1/P \times h_1 \times L_0 \times h_0 \times h_2\ousetarrow{T}{TO} L_1 \times h_1 \times L_0/P \times h_0 \times h_2$
%       \State \mbox{$L_1/P \times h_1 \times L_0 \times h_0 \times h_2$} \mbox{$\ousetarrow{T}{TO} L_1 \times h_1 \times L_0/P \times h_0 \times h_2$}
      \State
      \State $h_0 \gets \bigtimes_{s=r-t}^{r-1} \hat N_{s+1}/P_s \times \bigtimes_{s=0}^{r-t-1} N_s/P_s$
      \State $N   \gets \hat N_{r-t}$
      \State $h_1 \gets \bigtimes_{s=r+1}^{d-1} \hat N_s \times h$
      \State $\hat N \times h_0 \times h_1 \ousetarrow{FFT}{TI} h_0 \times N \times h_1 $
    \EndFor
    \For{$t\gets d-r-2,\hdots,0$}
      \State $h_0 \gets \bigtimes_{s=0}^{r-1} N_s/P_s \times \bigtimes_{s=r}^{d-2-t} N_s$
      \State $N   \gets \hat N_{d-1-t}$
      \State $h_1 \gets \bigtimes_{s=d-t}^{d-1} \hat N_s \times h$
      \State $h_0 \times \hat N \times h_1 \osetarrow{FFT} h_0 \times N \times h_1$
    \EndFor
  \end{algorithmic}
  \caption{Parallel Backward FFT Framework}\label{fig:fft_back}
\end{figure}

\newpage
\subsection{Backward Framework A (transposed input) - General \texorpdfstring{$r$, $d$}{r, d}}
\setlength{\arraycolsep}{2pt}
\begin{equation*}
  \begin{array}{cc}
    & \frac{\hat N_1}{P_0} \times \hdots \times \frac{\hat N_r}{P_{r-1}} \times \hat N_0 \times \hat N_{r+1} \times \hdots \times \hat N_{d-1} \times h \\
    \ousetarrow{FFT}{TO} & N_0 \times \frac{\hat N_1}{P_0} \times \hdots \times \frac{\hat N_r}{P_{r-1}} \times \hat N_{r+1} \times \hdots \times \hat N_{d-1} \times h \\
    \transposearrow{TI} & \frac{N_0}{P_0} \times \hat N_1 \times \frac{\hat N_2}{P_1} \times \hdots \times \frac{\hat N_r}{P_{r-1}} \times \hat N_{r+1} \times \hdots \times \hat N_{d-1} \times h \\
    \ousetarrow{FFT}{TO} & N_1 \times \frac{N_0}{P_0} \times \frac{\hat N_2}{P_1} \times \hdots \times \frac{\hat N_r}{P_{r-1}} \times \hat N_{r+1} \times \hdots \times \hat N_{d-1} \times h \\
    \vdots & \\
    \transposearrow{TI} & \frac{N_{r-1}}{P_{r-1}} \times \hdots \times \frac{N_0}{P_0} \times \hat N_r \times \hat N_{r+1} \times \hdots \times \hat N_{d-1} \times h \\
    \ousetarrow{FFT}{\red{T}} & \frac{N_0}{P_0} \times \hdots \times \frac{N_{r-1}}{P_{r-1}} \times N_r \times \hat N_{r+1} \times \hdots \times \hat N_{d-1} \times h \\
    \ousetarrow{FFT}{} & \frac{N_0}{P_0} \times \hdots \times \frac{N_{r-1}}{P_{r-1}} \times N_r \times N_{r+1} \times \hat N_{r+2} \times \hdots \times \hat N_{d-1} \times h \\
    \vdots & \\
    \ousetarrow{FFT}{} & \frac{N_0}{P_0} \times \hdots \times \frac{N_{r-1}}{P_{r-1}} \times N_r \times N_{r+1} \times \hdots \times N_{d-1} \times h \\
  \end{array}
\end{equation*}

\newpage
\subsection{Backward Framework A (transposed input) for \texorpdfstring{$r=3$, $d=5$}{r=3 and d=5}}
\setlength{\arraycolsep}{2pt}
\begin{equation*}
  \begin{array}{cccc}
    & \left(\frac{\hat N_1}{P_0} \times \frac{\hat N_2}{P_1} \times \frac{\hat N_3}{P_2}\right) \times \hat N_0 \times \left(\hat N_4 \times h\right)
    & \ousetarrow{FFT}{TO} & \Big(N_0\Big) \times \left(\frac{\hat N_1}{P_0} \times \frac{\hat N_2}{P_1} \times \frac{\hat N_3}{P_2}\right) \times \left(\hat N_4 \times h\right) \\
    \transposearrow{TI} & \left(\frac{N_0}{P_0}\right) \times \hat N_1 \times \left(\frac{\hat N_2}{P_1} \times \frac{\hat N_3}{P_2} \times \hat N_4 \times h\right)
    & \ousetarrow{FFT}{TO} & \left(N_1 \times \frac{N_0}{P_0}\right) \times \left(\frac{\hat N_2}{P_1} \times \frac{\hat N_3}{P_2} \right) \times \left(\hat N_4 \times h\right) \\
    \transposearrow{TI} & \left(\frac{N_1}{P_1} \times \frac{N_0}{P_0}\right) \times \hat N_2 \times \left(\frac{\hat N_3}{P_2} \times \hat N_4 \times h \right)
    & \ousetarrow{FFT}{TO} & \left(N_2 \times \frac{N_1}{P_1} \times \frac{N_0}{P_0}\right) \times \left(\frac{\hat N_3}{P_2} \right) \times \left(\hat N_4 \times h\right) \\
    \transposearrow{TI} & \frac{N_2}{P_2} \times \frac{N_1}{P_1} \times \frac{N_0}{P_0} \times \left(\hat N_3 \times \hat N_4 \times h \right)
    & \ousetarrow{FFT}{\red{T}} & \frac{N_0}{P_0} \times \frac{N_1}{P_1} \times \frac{N_2}{P_2} \times N_3 \times N_4 \times h
  \end{array}
\end{equation*}
Last step need more general interface to serial FFT module!

\subsection{Backward Framework B (transposed input and output) for \texorpdfstring{$r=3$, $d=5$}{r=3 and d=5}}
\setlength{\arraycolsep}{2pt}
\begin{equation*}
  \begin{array}{cccc}
    & \left(\frac{\hat N_1}{P_0} \times \frac{\hat N_2}{P_1} \times \frac{\hat N_3}{P_2}\right) \times \hat N_0 \times \left(\hat N_4 \times h\right)
    & \ousetarrow{FFT}{TO} & \Big(N_0\Big) \times \left(\frac{\hat N_1}{P_0} \times \frac{\hat N_2}{P_1} \times \frac{\hat N_3}{P_2}\right) \times \left(\hat N_4 \times h\right) \\
    \transposearrow{TIO} & \hat N_1 \times \left(\frac{\hat N_2}{P_1} \times \frac{\hat N_3}{P_2} \times \frac{N_0}{P_0}\right) \times \left(\hat N_4 \times h\right)
    & \osetarrow{FFT} & \Big(N_1\Big) \times \left(\frac{\hat N_2}{P_1} \times \frac{\hat N_3}{P_2} \times \frac{N_0}{P_0}\right) \times \left(\hat N_4 \times h\right) \\
    \transposearrow{TIO} & \hat N_2 \times \left(\frac{\hat N_3}{P_2} \times \frac{N_0}{P_0} \times \frac{N_1}{P_1}\right) \times \left(\hat N_4 \times h\right)
    & \osetarrow{FFT} & \Big(N_2\Big) \times \left(\frac{\hat N_3}{P_2} \times \frac{N_0}{P_0} \times \frac{N_1}{P_1}\right) \times \left(\hat N_4 \times h\right) \\
    \transposearrow{TIO} & \hat N_3 \times \left(\frac{N_0}{P_0} \times \frac{N_1}{P_1}  \times \frac{N_2}{P_2}\right) \times \left(\hat N_4 \times h\right)
    & \ousetarrow{FFT}{TI} & \frac{N_0}{P_0} \times \frac{N_1}{P_1}  \times \frac{N_2}{P_2} \times N_3 \times N_4 \times h
  \end{array}
\end{equation*}

\subsection{Forward Framework A (transposed input) for \texorpdfstring{$r=3$, $d=5$}{r=3 and d=5}}
\setlength{\arraycolsep}{2pt}
\begin{equation*}
  \begin{array}{cccc}
    & \left(\frac{N_0}{P_0} \times \frac{N_1}{P_1}  \times \frac{N_2}{P_2}\right) \times N_3 \times \left(\hat N_4 \times h\right)
    & \ousetarrow{FFT}{TO} & \left(\hat N_3 \times \frac{N_0}{P_0} \times \frac{N_1}{P_1}\right) \times \left(\frac{N_2}{P_2}\right) \times \left(\hat N_4 \times h\right) \\
    \transposearrow{TI} & \left(\frac{\hat N_3}{P_2} \times \frac{N_0}{P_0} \times \frac{N_1}{P_1}\right)  \times N_2 \times \left(\hat N_4 \times h\right)
    & \ousetarrow{FFT}{TO} & \left(\hat N_2 \times \frac{\hat N_3}{P_2} \times \frac{N_0}{P_0}\right) \times \left(\frac{N_1}{P_1}\right) \times \left(\hat N_4 \times h\right) \\
    \transposearrow{TI} & \left(\frac{\hat N_2}{P_1} \times \frac{\hat N_3}{P_2} \times \frac{N_0}{P_0}\right) \times N_1 \times \left(\hat N_4 \times h\right)
    & \ousetarrow{FFT}{TO} & \left(\hat N_1 \times \frac{\hat N_2}{P_1} \times \frac{\hat N_3}{P_2}\right) \times \left(\frac{N_0}{P_0}\right) \times \left(\hat N_4 \times h\right) \\
    \transposearrow{TI} & \left(\frac{\hat N_1}{P_0} \times \frac{\hat N_2}{P_1} \times \frac{\hat N_3}{P_2}\right) \times N_0 \times \left(\hat N_4 \times h\right)
    & \osetarrow{FFT} & \frac{\hat N_1}{P_0} \times \frac{\hat N_2}{P_1} \times \frac{\hat N_3}{P_2} \times \hat N_0 \times \hat N_4 \times h
  \end{array}
\end{equation*}

\subsection{Forward Framework B (transposed input and output) for \texorpdfstring{$r=3$, $d=5$}{r=3 and d=5}}
\setlength{\arraycolsep}{2pt}
\begin{equation*}
  \begin{array}{cccc}
    & \left(\frac{N_0}{P_0} \times \frac{N_1}{P_1}  \times \frac{N_2}{P_2}\right) \times N_3 \times \left(N_4 \times h\right)
    & \ousetarrow{FFT}{TO} & \left(\hat N_3 \times \frac{N_0}{P_0} \times \frac{N_1}{P_1}\right)  \times \left(\frac{N_2}{P_2}\right) \times \left(\hat N_4 \times h\right) \\
    \transposearrow{TIO} & N_2 \times \left(\frac{\hat N_3}{P_2} \times \frac{N_0}{P_0} \times \frac{N_1}{P_1} \right) \times \left( \hat N_4 \times h\right)
    & \osetarrow{FFT} & \left(\hat N_2 \times \frac{\hat N_3}{P_2} \times \frac{N_0}{P_0}\right) \times \left(\frac{N_1}{P_1}\right) \times \left(\hat N_4 \times h\right) \\
    \transposearrow{TIO} & N_1 \times \left(\frac{\hat N_2}{P_1} \times \frac{\hat N_3}{P_2} \times \frac{N_0}{P_0}\right) \times \left( \hat N_4 \times h\right)
    & \osetarrow{FFT} & \left(\hat N_1 \times \frac{\hat N_2}{P_1} \times \frac{\hat N_3}{P_2}\right) \times \left(\frac{N_0}{P_0}\right) \times \left(\hat N_4 \times h\right) \\
    \transposearrow{TIO} & N_0 \times \left(\frac{\hat N_1}{P_0} \times \frac{\hat N_2}{P_1} \times \frac{\hat N_3}{P_2}\right) \times \left(\hat N_4 \times h\right)
    & \ousetarrow{FFT}{TI} & \frac{\hat N_1}{P_0} \times \frac{\hat N_2}{P_1} \times \frac{\hat N_3}{P_2} \times \hat N_0 \times \hat N_4 \times h
  \end{array}
\end{equation*}

\newpage
\subsection{Backward Framework A (transposed input) - The general form}
\figurename{}~\ref{fig:fft_back_A} lists the parallel backward FFT framework A in pseudo code.
\begin{figure}[ht]
  \begin{algorithmic}[1]
  %   \State\Comment{Calculate the serial FFTs row wise}
    \For{$t\gets 0,\hdots,r-1$}
      \State $h_0 \gets \bigtimes_{s=t}^{r-1}\hat N_{s+1}/P_s$
      \State $N   \gets \hat N_t$
      \State $h_1 \gets \bigtimes_{s=t+1}^{r-1} \hat N_{s+1}/ P_{s} \times \hat N_{r}  \bigtimes_{s=r+1}^{d-1} \hat N_s \times h$
      \State $h_0 \times \hat N \times h_1 \ousetarrow{FFT}{TO} N \times h_0 \times h_1$
      \State
      \State $L_1 \gets N_t$
      \State $h_1 \gets \bigtimes_{s=0}^{t-1} N_{s}/P_{s}$
      \State $L_0 \gets \hat N_{t+1}$
      \State $h_0 \gets \bigtimes_{s=t+1}^{r-1}\hat N_{s+1}/P_{s}$
      \State $h_2 \gets \bigtimes_{s=r+1}^{d-1} \hat N_s \times h$
      \State $P   \gets P_{t}$
      \State $L_1 \times h_1 \times L_0/P \times h_0 \times h_2\ousetarrow{T}{TI} L_1/P \times h_1 \times L_0 \times h_0 \times h_2$
    \EndFor
    \State $h_0 \gets \bigtimes_{s=r-t}^{r-1} \hat N_{s+1}/P_s \times \bigtimes_{s=0}^{r-t-1} N_s/P_s$
    \State $N   \gets \hat N_{r-t}$
    \State $h_1 \gets \bigtimes_{s=r+1}^{d-1} \hat N_s \times h$
    \State $\hat N \times h_0 \times h_1 \ousetarrow{FFT}{TI} h_0 \times N \times h_1 $
    \For{$t\gets d-r-2,\hdots,0$}
      \State $h_0 \gets \bigtimes_{s=0}^{r-1} N_s/P_s \times \bigtimes_{s=r}^{d-2-t} N_s$
      \State $N   \gets \hat N_{d-1-t}$
      \State $h_1 \gets \bigtimes_{s=d-t}^{d-1} \hat N_s \times h$
      \State $h_0 \times \hat N \times h_1 \osetarrow{FFT} h_0 \times N \times h_1$
    \EndFor
  \end{algorithmic}
  \caption{Parallel Backward FFT Framework A}\label{fig:fft_back_A}
\end{figure}


\begin{compactitem}
  \item[\mybox] \verb+#include <complex.h> #include <pfft.h>+
\end{compactitem}


\section{Precisions}\label{sec:prec}
This section an analog to part~\cite{fftw-prec} of the FFTW manual.

You can install single and long-double precision versions of PFFT, which replace double with float and long double, respectively; see \ref{sec:install}.
To use these interfaces, you must
\begin{compactitem}
  \item Link to the single/long-double libraries; on Unix, \code{-lpfftf} or \code{-lpfftl} instead of (or in addition to) \code{-lpfft}.
        (You can link to the different-precision libraries simultaneously.)
  \item Include the same \code{<pfft.h>} header file.
  \item Replace all lowercase instances of ‘\code{pfft_}’ with ‘\code{pfftf_}’ or ‘\code{pfftl_}’ for single or long-double precision, respectively.
        (\code{pfft_complex} becomes \code{pfftf_complex}, \code{pfft_execute} becomes \code{pfftf_execute}, etcetera.)
  \item Uppercase names, i.e. names beginning with ‘\code{PFFT_}’, remain the same.
  \item Replace double with float or long double for subroutine parameters.
\end{compactitem}

\section{Complex numbers}
PFFT introduces the complex data type \code{pfft_complex} that is nothing else than a typedef to \code{fftw_complex}.
According to the FFTW manual~\cite{fftw-cplx-num}:
\begin{quote}
  The default FFTW interface uses double precision for all floating-point numbers, and defines a \code{fftw_complex} type to hold complex numbers as:
  \begin{lstlisting}
    typedef double fftw_complex[2];
  \end{lstlisting}
  Here, the \code{[0]} element holds the real part and the \code{[1]} element holds the imaginary part.

  Alternatively, if you have a C compiler (such as gcc) that supports the C99 revision of the ANSI C standard,
  you can use C's new native complex type (which is binary-compatible with the typedef above).
  In particular, if you \code{#include <complex.h>} before \code{<fftw.h>}, then \code{fftw_complex} is defined to be the native complex
  type and you can manipulate it with ordinary arithmetic (e.g. x = y * (3+4*I), where x and y are \code{fftw_complex}
  and I is the standard symbol for the imaginary unit);
\end{quote}
I.e., include \code{<complex.h>} \emph{before} \code{<pfft.h>}, \code{<fftw.h>} and \code{<fftw-mpi.h>} to be sure that \code{pfft_complex} is defined to be the native complex.

\section{Measuring parallel run times}
Use \code{MPI_Barrier} in front of every call to \code{pfft_} function to avoid unbalanced run times.
